{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Code_Permission.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN7J8LDlvoV2jD5J0ltzt7f"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"hF8xFIpHPLRw"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3-3Tvy93Q29h"},"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import sklearn as sk\n","import torch.nn as nn                     \n","import torch.nn.functional as F\n","import torch.optim as optim\n","import pickle\n","import xlwt\n","from collections import Counter \n","from xlwt import Workbook \n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier  \n","from sklearn.metrics import classification_report\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import f1_score\n","from random import randint\n","from keras.models import Sequential, Model\n","from keras.layers import Input, Dense, Reshape, LSTM, Lambda, BatchNormalization, GaussianNoise, Flatten\n","from keras.layers.merge import Add, Multiply\n","from keras.optimizers import Adam\n","import keras.backend as KB\n","import random\n","from collections import deque\n","from keras.initializers import RandomUniform\n","from tqdm import tqdm\n","import tensorflow as tf\n","tf.compat.v1.disable_eager_execution()\n","from keras.layers import concatenate\n","from sklearn import tree\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import svm\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","import xgboost as xgb\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import StackingClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2lbpkNrAQ4BH"},"source":["path = '/content/gdrive/MyDrive/New Dataset/'\n","benign_src = path + 'Permission_benign.csv'\n","malware_src = path + 'Permission_malware.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zsR2YvbUvgI7"},"source":["benign = pd.read_csv(benign_src)\n","malware = pd.read_csv(malware_src)\n","# Add Class Label to Benign and Malware Instances\n","benign['Class'] = 0\n","malware['Class'] = 1\n","print(benign.info())\n","print(malware.info())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tr9nsKQkvkbf"},"source":["# Rename 1st Column as ID\n","malware.rename( columns={'Unnamed: 0':'ID'}, inplace=True )\n","benign.rename( columns={'Unnamed: 0':'ID'}, inplace=True )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JIImoRsHwIPK"},"source":["# Combine Benign and Malware Instances\n","combined = pd.concat([benign, malware],ignore_index=True)\n","print(combined.info)\n","permission_number = 0\n","permissions = {}\n","for column in combined.columns:\n","  if column != 'ID' and column != 'Class':\n","    permissions[permission_number] = column\n","    permission_number = permission_number + 1\n","print(permissions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cuwBkJhPwLE9"},"source":["# Split Data into X and Y\n","X = combined.loc[:,combined.columns != 'Class']\n","X = X.loc[:,X.columns != 'ID']\n","Y = combined.loc[:, combined.columns == 'Class']\n","X = pd.DataFrame(X).to_numpy()\n","Y = pd.DataFrame(Y).to_numpy()\n","print(X.shape)\n","print(Y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VGIGL8LHwcFU"},"source":["**Define Classifiers**"]},{"cell_type":"code","metadata":{"id":"v9g2cEiVwRSe"},"source":["def classifyRF(X_train,X_test,Y_train,Y_test):\n","  # Define Random Forest Classifier and Fit on Data\n","  rf_classifier = RandomForestClassifier()\n","  rf_classifier = rf_classifier.fit(X_train,Y_train)\n","  Y_pred = rf_classifier.predict(X_test)\n","  # Return Stats\n","  accuracy = accuracy_score(Y_test,Y_pred)\n","  precision = precision_score(Y_test,Y_pred)\n","  recall = recall_score(Y_test,Y_pred)\n","  f1 = f1_score(Y_test,Y_pred)\n","  return (rf_classifier,accuracy,precision,recall,f1, Y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7MNlA4wbwrI-"},"source":["def classifyDT(X_train,X_test,Y_train,Y_test):\n","  # Define Decision Tree Classifier and Fit on Data\n","  dt_classifier = tree.DecisionTreeClassifier()\n","  dt_classifier = dt_classifier.fit(X_train,Y_train)\n","  Y_pred = dt_classifier.predict(X_test)\n","  # Return Stats\n","  accuracy = accuracy_score(Y_test,Y_pred)\n","  precision = precision_score(Y_test,Y_pred)\n","  recall = recall_score(Y_test,Y_pred)\n","  f1 = f1_score(Y_test,Y_pred)\n","  return (dt_classifier,accuracy,precision,recall,f1, Y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"anFbBcZFwuSH"},"source":["def classifyBNB(X_train,X_test,Y_train,Y_test):\n","  # Define Bernoulli Naive Bayes Classifier and Fit on Data\n","  bnb_classifier = BernoulliNB()\n","  bnb_classifier = bnb_classifier.fit(X_train,Y_train)\n","  Y_pred = bnb_classifier.predict(X_test)\n","  # Return Stats\n","  accuracy = accuracy_score(Y_test,Y_pred)\n","  precision = precision_score(Y_test,Y_pred)\n","  recall = recall_score(Y_test,Y_pred)\n","  f1 = f1_score(Y_test,Y_pred)\n","  return (bnb_classifier,accuracy,precision,recall,f1, Y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-BdG1WeWwxZI"},"source":["def classifySVM(X_train,X_test,Y_train,Y_test):\n","  # Define Support Vector Machine Classifier and Fit on Data\n","  svm_classifier = svm.SVC(probability=True)\n","  svm_classifier = svm_classifier.fit(X_train,Y_train)\n","  Y_pred = svm_classifier.predict(X_test)\n","  # Return Stats\n","  accuracy = accuracy_score(Y_test,Y_pred)\n","  precision = precision_score(Y_test,Y_pred)\n","  recall = recall_score(Y_test,Y_pred)\n","  f1 = f1_score(Y_test,Y_pred)\n","  return (svm_classifier,accuracy,precision,recall,f1, Y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cdDL7MaXw0dE"},"source":["def classifyLR(X_train,X_test,Y_train,Y_test):\n","  # Define Logistic Regression Classifier and Fit on Data\n","  lr_classifier = LogisticRegression()\n","  lr_classifier = lr_classifier.fit(X_train,Y_train)\n","  Y_pred = lr_classifier.predict(X_test)\n","  # Return Stats\n","  accuracy = accuracy_score(Y_test,Y_pred)\n","  precision = precision_score(Y_test,Y_pred)\n","  recall = recall_score(Y_test,Y_pred)\n","  f1 = f1_score(Y_test,Y_pred)\n","  return (lr_classifier,accuracy,precision,recall,f1, Y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0cLKViSHw3BZ"},"source":["def classifyGB(X_train,X_test,Y_train,Y_test):\n","  # Define Gradient Boost Classifier and Fit on Data\n","  gb_classifier = GradientBoostingClassifier()\n","  gb_classifier = gb_classifier.fit(X_train,Y_train)\n","  Y_pred = gb_classifier.predict(X_test)\n","  # Return Stats\n","  accuracy = accuracy_score(Y_test,Y_pred)\n","  precision = precision_score(Y_test,Y_pred)\n","  recall = recall_score(Y_test,Y_pred)\n","  f1 = f1_score(Y_test,Y_pred)\n","  return (gb_classifier,accuracy,precision,recall,f1, Y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z1CTuCjIw6Rw"},"source":["def classifyXGB(X_train,X_test,Y_train,Y_test):\n","  # Define Extreme Gradient Boost Classifier and Fit on Data\n","  xgb_classifier = xgb.XGBClassifier()\n","  xgb_classifier = xgb_classifier.fit(X_train,Y_train)\n","  Y_pred = xgb_classifier.predict(X_test)\n","  # Return Stats\n","  accuracy = accuracy_score(Y_test,Y_pred)\n","  precision = precision_score(Y_test,Y_pred)\n","  recall = recall_score(Y_test,Y_pred)\n","  f1 = f1_score(Y_test,Y_pred)\n","  return (xgb_classifier,accuracy,precision,recall,f1, Y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SrAzHwXWw87c"},"source":["def classifyStack(X_train,X_test,Y_train,Y_test):\n","  # Define Stacked Classifier and Fit on Data\n","  estimators = [('svm',svm.SVC()),\n","                ('dt',tree.DecisionTreeClassifier())]\n","  stack_classifier = StackingClassifier(estimators=estimators)\n","  stack_classifier = stack_classifier.fit(X_train,Y_train)\n","  Y_pred = stack_classifier.predict(X_test)\n","  # Return Stats\n","  accuracy = accuracy_score(Y_test,Y_pred)\n","  precision = precision_score(Y_test,Y_pred)\n","  recall = recall_score(Y_test,Y_pred)\n","  f1 = f1_score(Y_test,Y_pred)\n","  return (stack_classifier,accuracy,precision,recall,f1, Y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SRSngL6sxAc5"},"source":["def classifyDNN1(X_train,X_test,Y_train,Y_test):\n","  # Define Deep Neural Network Classifier with 1 hidden layer and Fit on Data\n","  dnn_classifier = MLPClassifier(hidden_layer_sizes=(64),max_iter=350)\n","  dnn_classifier = dnn_classifier.fit(X_train,Y_train)\n","  Y_pred = dnn_classifier.predict(X_test)\n","  # Return Stats\n","  accuracy = accuracy_score(Y_test,Y_pred)\n","  precision = precision_score(Y_test,Y_pred)\n","  recall = recall_score(Y_test,Y_pred)\n","  f1 = f1_score(Y_test,Y_pred)\n","  return (dnn_classifier,accuracy,precision,recall,f1, Y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTBTc97BxDHJ"},"source":["def classifyDNN3(X_train,X_test,Y_train,Y_test):\n","  # Define Deep Neural Network Classifier with 3 hidden layer and Fit on Data\n","  dnn_classifier = MLPClassifier(hidden_layer_sizes=(64,32,16))\n","  dnn_classifier = dnn_classifier.fit(X_train,Y_train)\n","  Y_pred = dnn_classifier.predict(X_test)\n","  # Return Stats\n","  accuracy = accuracy_score(Y_test,Y_pred)\n","  precision = precision_score(Y_test,Y_pred)\n","  recall = recall_score(Y_test,Y_pred)\n","  f1 = f1_score(Y_test,Y_pred)\n","  return (dnn_classifier,accuracy,precision,recall,f1, Y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IN_ymA95xGK6"},"source":["def classifyDNN5(X_train,X_test,Y_train,Y_test):\n","  # Define Deep Neural Network Classifier with 5 hidden layer and Fit on Data\n","  dnn_classifier = MLPClassifier(hidden_layer_sizes=(128,64,32,16,8))\n","  dnn_classifier = dnn_classifier.fit(X_train,Y_train)\n","  Y_pred = dnn_classifier.predict(X_test)\n","  # Return Stats\n","  accuracy = accuracy_score(Y_test,Y_pred)\n","  precision = precision_score(Y_test,Y_pred)\n","  recall = recall_score(Y_test,Y_pred)\n","  f1 = f1_score(Y_test,Y_pred)\n","  return (dnn_classifier,accuracy,precision,recall,f1, Y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HpXJ9AKoxJu4"},"source":["**Define Environment for RL**"]},{"cell_type":"code","metadata":{"id":"jisEc5pTxIok"},"source":["class Env():\n","  def __init__(self,num_features,model):\n","    # Define Classifier and Number of Features Used\n","    self.num_features = num_features\n","    self.model = model\n","    # Extract only Malware Instances\n","    #(self.X,self.Y) = self.correlation_select(self.num_features)\n","    #(self.X,self.Y) = self.univariate_select(self.num_features)\n","    self.X = np.copy(X)\n","    self.Y = np.copy(Y)\n","    self.indices = np.where(self.Y == 1)\n","    self.data = self.X[self.indices[0]]\n","    # Split Malware Instances into Train and Test Data\n","    #self.train_size = int(np.rint(self.data.shape[0] * 0.8))\n","    #self.train_data = self.data[:self.train_size,:]\n","    #self.test_data = self.data[self.train_size:,:]\n","    self.train_data = np.copy(self.data)\n","    self.test_data = np.copy(self.data)\n","    # Define Observation Space, Action Space, State, Action, Reward Variables\n","    self.observation_space = num_features\n","    self.action_space = num_features\n","    self.action_range = 1\n","    self.state = np.zeros((self.num_features,1))\n","    self.action = randint(0,self.action_space)\n","    self.selected = np.zeros((self.train_data.shape[0],1))\n","    self.done = 0\n","    self.reward = 0\n","    self.num = 0\n","  \n","  def univariate_select(self,num_features):\n","    # Choose Top K Features Based on Chi Squared Test\n","    selector = SelectKBest(chi2, k=num_features)\n","    combined_topK = combined.loc[:,combined.columns != 'Class']\n","    combined_topK = combined_topK.loc[:,combined_topK.columns != 'ID']\n","    Y_topK = combined.loc[:,combined.columns == 'Class']\n","    X_topK = selector.fit_transform(combined_topK,Y_topK)\n","    return (X_topK,Y_topK)\n","\n","  def correlation_select(self,num_features):\n","    # Choose Top K Features Based on Correlation with Class Label\n","    X = combined.loc[:,combined.columns != 'Class']\n","    X = X.loc[:,X.columns != 'ID']\n","    X = X.loc[:, (X != 0).any(axis=0)]\n","    Y = combined.loc[:, combined.columns == 'Class']\n","    X = pd.DataFrame(X).to_numpy()\n","    Y = pd.DataFrame(Y).to_numpy()\n","    XY = np.concatenate((X,Y),axis = 1)\n","    corr = np.corrcoef(XY.T)\n","    target_corr = corr[:][-1]\n","    target_corr = np.absolute(target_corr)\n","    target_corr = target_corr[0:len(target_corr) - 1]\n","    index = target_corr.argsort()\n","    X_topK = X[:,index[::-1][:num_features]]\n","    Y_topK = Y\n","    return (X_topK,Y_topK)\n","  \n","  def reset(self):\n","    # Start New Episode of Training by Choosing a New Malware Instance Randomly\n","    self.done = 0\n","    while True:\n","      # If all Instances Seen, Reset All to Unseen and Choose Randomly Again\n","      result = np.max(self.selected) == np.min(self.selected)\n","      if result:\n","        self.selected = np.zeros((self.train_data.shape[0],1))\n","      self.num = randint(0,self.train_data.shape[0] - 1)\n","      if(self.selected[self.num] == 0):\n","        self.selected[self.num] = 1\n","        self.state = self.train_data[self.num]\n","        break\n","      else:\n","        continue\n","    return self.state\n","  \n","  def step(self,action):\n","    # Take an Action\n","    prev_obs = np.zeros((self.num_features,))\n","    next_obs = np.zeros((self.num_features,))\n","    prev_obs[:] = self.state[:]\n","    # Penalise Agent for Taking Same Action Again and Return Next State, Action, Reward\n","    if self.state[action] == 1:\n","      (self.reward,self.done) = self.classify(prev_obs,prev_obs)\n","      self.reward = self.reward - 10\n","      return (self.state,self.reward,self.done)\n","    else:  \n","      self.state[action] = 1\n","      next_obs[:] = self.state[:]\n","      (self.reward,self.done) = self.classify(prev_obs,next_obs)\n","      return (self.state,self.reward,self.done)\n","\n","  def classify(self,prev_obs,next_obs):\n","    # Return Change in Class Probabilities After Taking Action as Reward and Done Variable\n","    prev_obs = prev_obs.reshape(1, -1)\n","    next_obs = next_obs.reshape(1, -1)\n","    self.prev = self.model.predict_proba(prev_obs)[0]\n","    self.next = self.model.predict_proba(next_obs)[0]\n","    self.reward = self.next[0] - self.prev[0]\n","    if self.next[0] > 0.50:\n","      self.done = 1\n","    else:\n","      self.done = 0\n","    return (self.reward,self.done)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_m3-XM2vxYSM"},"source":["**Define Actor Network + Target Actor Network**"]},{"cell_type":"code","metadata":{"id":"tx9Aj6xRxRej"},"source":["class Actor():\n","    # Actor Network\n","    def __init__(self, inp_dim, out_dim, act_range, lr, tau):\n","        # Define Input Output Dimensions\n","        self.env_dim = inp_dim\n","        self.act_dim = out_dim\n","        self.act_range = act_range\n","        # Define Hyperparameters\n","        self.tau = tau\n","        self.lr = lr\n","        # Define Actor Network and Target Actor Network\n","        self.model = self.network()\n","        self.target_model = self.network()\n","        # Define Optimizer Used\n","        self.adam_optimizer = self.optimizer()\n","\n","    def network(self):\n","        # Define Actor Network Architecture\n","        inp = Input(shape=(self.env_dim,))\n","        x = Dense(256, activation='relu')(inp)\n","        #x = GaussianNoise(1.0)(x)\n","        #x = Dense(80, activation='relu')(x)\n","        #x = GaussianNoise(1.0)(x)\n","        #x = Dense(160, activation='relu')(x)\n","        #x = Dense(80, activation='relu')(x)\n","        x = Dense(128, activation='relu')(x)\n","        #x = GaussianNoise(1.0)(x)\n","        out = Dense(self.act_dim, activation='softmax')(x)\n","        return Model(inp, out)\n","\n","    def predict(self, state):\n","        # Predict Action Taken By Actor Network\n","        return self.model.predict(np.expand_dims(state, axis=0))\n","\n","    def target_predict(self, inp):\n","        # Predict Action Taken By Target Actor Network\n","        return self.target_model.predict(inp)\n","\n","    def transfer_weights(self):\n","        # Transfer Actor Network Weights to Target Actor Network with a Factor of Tau\n","        (W, target_W) = self.model.get_weights(), self.target_model.get_weights()\n","        for i in range(len(W)):\n","            target_W[i] = self.tau * W[i] + (1 - self.tau)* target_W[i]\n","        self.target_model.set_weights(target_W)\n","\n","    def train(self, states, actions, grads):\n","        # Train Actor Network\n","        self.adam_optimizer([states, grads])\n","\n","    def optimizer(self):\n","        # Define Optimizer\n","        action_gdts = KB.placeholder(shape=(None, self.act_dim))\n","        params_grad = tf.gradients(self.model.output, self.model.trainable_weights, -action_gdts)\n","        grads = zip(params_grad, self.model.trainable_weights)\n","        return KB.function(inputs=[self.model.input, action_gdts], outputs=[KB.constant(1)], updates= [tf.optimizers.Adam(self.lr).apply_gradients(grads)])\n","\n","    def save(self, path):\n","        # Save Model Weights\n","        self.model.save_weights(path + '_actor.h5')\n","\n","    def load_weights(self, path):\n","        # Load Model Weights\n","        self.model.load_weights(path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IQO8faVNxj4V"},"source":["**Define Critic Network + Target Critic Network**"]},{"cell_type":"code","metadata":{"id":"jWhMEO-exefd"},"source":["class Critic():\n","    # Critic Network\n","    def __init__(self, inp_dim, out_dim, lr, tau):\n","        # Define Input Output Dimensions\n","        self.env_dim = inp_dim\n","        self.act_dim = out_dim\n","        # Define Hyperparameters\n","        self.tau, self.lr = tau, lr\n","        # Define Critic Network and Target Critic Network\n","        self.model = self.network()\n","        self.target_model = self.network()\n","        self.model.compile(Adam(self.lr), 'mse')\n","        self.target_model.compile(Adam(self.lr), 'mse')\n","        # Function to Compute Q-value Gradients (Needed for Actor Optimization)\n","        self.action_grads = tf.keras.backend.function([self.model.input[0], self.model.input[1]], tf.keras.backend.gradients(self.model.output, [self.model.input[1]]))\n","\n","    def network(self):\n","        # Define Critic Network Architecture\n","        state = Input(shape=(self.env_dim,))\n","        action = Input(shape=(self.act_dim,))\n","        x = Dense(256, activation='relu')(state)\n","        x = concatenate([x, action])\n","        x = Dense(128, activation='relu')(x)\n","        #x = Dense(160, activation='relu')(x)\n","        #x = Dense(80, activation='relu')(x)\n","        #x = Dense(40, activation='relu')(x)\n","        out = Dense(1, activation='linear', kernel_initializer=RandomUniform())(x)\n","        return Model([state, action], out)\n","\n","    def gradients(self, states, actions):\n","        # Compute Q-value Gradients w.r.t. States and Actions\n","        return self.action_grads([states, actions])\n","\n","    def target_predict(self, inp):\n","        # Predict Q Values Using Target Critic Network\n","        return self.target_model.predict(inp)\n","\n","    def train_on_batch(self, states, actions, critic_target):\n","        # Train Critic Network\n","        return self.model.train_on_batch([states, actions], critic_target)\n","\n","    def transfer_weights(self):\n","        # Transfer Critic Network Weights to Target Critic Network with a Factor of Tau\n","        (W, target_W) = self.model.get_weights(), self.target_model.get_weights()\n","        for i in range(len(W)):\n","            target_W[i] = self.tau * W[i] + (1 - self.tau)* target_W[i]\n","        self.target_model.set_weights(target_W)\n","\n","    def save(self, path):\n","        # Save Model Weights\n","        self.model.save_weights(path + '_critic.h5')\n","\n","    def load_weights(self, path):\n","        # Load Model Weights\n","        self.model.load_weights(path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1FmiS9Apxs8E"},"source":["**Sum Tree Data Structure for Efficient Memory Usage**"]},{"cell_type":"code","metadata":{"id":"z4fUtbTCxoNS"},"source":["class SumTree():\n","    write = 0\n","\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.tree = np.zeros( 2*capacity - 1 )\n","        self.data = np.zeros( capacity, dtype=object )\n","\n","    def _propagate(self, idx, change):\n","        parent = (idx - 1) // 2\n","\n","        self.tree[parent] += change\n","\n","        if parent != 0:\n","            self._propagate(parent, change)\n","\n","    def _retrieve(self, idx, s):\n","        left = 2 * idx + 1\n","        right = left + 1\n","\n","        if left >= len(self.tree):\n","            return idx\n","\n","        if s <= self.tree[left]:\n","            return self._retrieve(left, s)\n","        else:\n","            return self._retrieve(right, s-self.tree[left])\n","\n","    def total(self):\n","        return self.tree[0]\n","\n","    def add(self, p, data):\n","        idx = self.write + self.capacity - 1\n","\n","        self.data[self.write] = data\n","        self.update(idx, p)\n","\n","        self.write += 1\n","        if self.write >= self.capacity:\n","            self.write = 0\n","\n","    def update(self, idx, p):\n","        change = p - self.tree[idx]\n","\n","        self.tree[idx] = p\n","        self._propagate(idx, change)\n","\n","    def get(self, s):\n","        idx = self._retrieve(0, s)\n","        dataIdx = idx - self.capacity + 1\n","\n","        return (idx, self.tree[idx], self.data[dataIdx])\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pUpzuBkhx2Tx"},"source":["**Memory Buffer for Experience Replay**"]},{"cell_type":"code","metadata":{"id":"GBnl5gEBxw_U"},"source":["class MemoryBuffer(object):\n","    # Memory Buffer Class for Experience Replay Using Deque (Normal) or Sum Tree (Priority)\n","    def __init__(self, buffer_size, with_per = False):\n","        # Initialization\n","        if(with_per):\n","            # Prioritized Experience Replay\n","            self.alpha = 0.5\n","            self.epsilon = 0.01\n","            self.buffer = SumTree(buffer_size)\n","        else:\n","            # Standard Buffer\n","            self.buffer = deque()\n","        self.count = 0\n","        self.with_per = with_per\n","        self.buffer_size = buffer_size\n","\n","    def memorize(self, state, action, reward, done, new_state, error=None):\n","        # Save an Experience to Memory, Optionally with its TD-Error \n","        experience = (state, action, reward, done, new_state)\n","        if(self.with_per):\n","            priority = self.priority(error[0])\n","            self.buffer.add(priority, experience)\n","            self.count += 1\n","        else:\n","            # Check if Buffer is Already Full\n","            if self.count < self.buffer_size:\n","                self.buffer.append(experience)\n","                self.count += 1\n","            else:\n","                self.buffer.popleft()\n","                self.buffer.append(experience)\n","\n","    def priority(self, error):\n","        # Compute Priority of Experience\n","        return (error + self.epsilon) ** self.alpha\n","\n","    def size(self):\n","        # Return Current Size of Buffer\n","        return self.count\n","\n","    def sample_batch(self, batch_size):\n","        # Sample a Batch\n","        batch = []\n","\n","        # Sample using Prorities\n","        if(self.with_per):\n","            T = self.buffer.total() // batch_size\n","            for i in range(batch_size):\n","                a, b = T * i, T * (i + 1)\n","                s = random.uniform(a, b)\n","                idx, error, data = self.buffer.get(s)\n","                batch.append((*data, idx))\n","            idx = np.array([i[5] for i in batch])\n","        # Sample Randomly from Buffer\n","        elif self.count < batch_size:\n","            idx = None\n","            batch = random.sample(self.buffer, self.count)\n","        else:\n","            idx = None\n","            batch = random.sample(self.buffer, batch_size)\n","\n","        # Return a Batch of Experiences\n","        s_batch = np.array([i[0] for i in batch])\n","        a_batch = np.array([i[1] for i in batch])\n","        r_batch = np.array([i[2] for i in batch])\n","        d_batch = np.array([i[3] for i in batch])\n","        new_s_batch = np.array([i[4] for i in batch])\n","        return s_batch, a_batch, r_batch, d_batch, new_s_batch, idx\n","\n","    def update(self, idx, new_error):\n","        # Update Priority of Experiences\n","        self.buffer.update(idx, self.priority(new_error))\n","\n","    def clear(self):\n","        # Clear Deque or Sum Tree\n","        if(self.with_per): self.buffer = SumTree(buffer_size)\n","        else: self.buffer = deque()\n","        self.count = 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bb38WcFUx_wv"},"source":["**Define Agent**"]},{"cell_type":"code","metadata":{"id":"qxQtWhTkx7Yk"},"source":["class Agent():\n","    \n","    def __init__(self, env, buffer_size = 20000,batch_size = 64, epsilon = 1.00, epsilon_decay = 0.9995, gamma = 0.99, lr = 0.00005, tau = 0.001, with_per = False):\n","        # Define Environment and Agent Parameters\n","        self.env = env\n","        self.action_dim = self.env.action_space\n","        self.action_range = self.env.action_range\n","        self.observation_dim = self.env.observation_space\n","        self.epsilon = epsilon\n","        self.epsilon_decay = epsilon_decay\n","        self.gamma = gamma\n","        self.lr = lr\n","        self.tau = tau\n","        self.buffer_size = buffer_size\n","        self.batch_size = batch_size\n","        self.with_per = with_per\n","        # Create Actor and Critic Networks\n","        self.actor = Actor(self.observation_dim,self.action_dim,self.action_range,0.1 * lr, tau)\n","        self.critic = Critic(self.observation_dim,self.action_dim, lr, tau)\n","        self.buffer = MemoryBuffer(self.buffer_size,self.with_per)\n","\n","    def policy_action(self, s):\n","        # Predict Action Using Actor Network\n","        return self.actor.predict(s)[0]\n","\n","    def bellman(self, rewards, q_values, dones):\n","        # Compute Critic Target Using Bellman Equation\n","        critic_target = np.asarray(q_values)\n","        for i in range(q_values.shape[0]):\n","            if dones[i]:\n","                critic_target[i] = rewards[i]\n","            else:\n","                critic_target[i] = rewards[i] + self.gamma * q_values[i]\n","        return critic_target\n","\n","    def memorize(self, state, action, reward, done, new_state):\n","        # Store Experience in Buffer \n","        self.buffer.memorize(state, action, reward, done, new_state)\n","\n","    def sample_batch(self, batch_size):\n","        # Return Batch of Experiences\n","        return self.buffer.sample_batch(batch_size)\n","\n","    def update_models(self, states, actions, critic_target):\n","        # Update Actor and Critic Models\n","        # Train Critic\n","        self.critic.train_on_batch(states, actions, critic_target)\n","        # Q-Value Gradients under Current Policy\n","        actions = self.actor.model.predict(states)\n","        grads = self.critic.gradients(states, actions)\n","        # Train Actor\n","        self.actor.train(states, actions, np.array(grads).reshape((-1, self.action_dim)))\n","        # Transfer Weights to Target Networks at Rate Tau\n","        self.actor.transfer_weights()\n","        self.critic.transfer_weights()\n","\n","    def train(self,num_episodes):\n","      # Train Agent for a Specified Number of Episodes \n","      num_alterations = []\n","      cumulative_rewards = []\n","      curr_state = np.zeros((self.observation_dim,))\n","      next_state = np.zeros((self.observation_dim,))\n","      for e in range(0,num_episodes):\n","        #print(\"Training Episode: \",e,self.epsilon)\n","        steps,cumulative_reward,done = 0,0,0\n","        curr_state[:] = self.env.reset()[:]\n","        while not done:\n","          randgen = random.random()\n","          #print(randgen)\n","          if(randgen < self.epsilon):\n","            act = np.random.rand(self.action_dim)\n","            s = np.sum(act)\n","            act = np.divide(act,s)\n","            #print(act)\n","            #print(np.sum(act))\n","            action = np.zeros((self.action_dim))\n","            #action[:] = act[:]\n","            act = np.argmax(act)\n","            #print(act)\n","            action[act] = 1\n","            #print(act)\n","          else:\n","            act = self.policy_action(curr_state)\n","            #chosen_action = np.arange(0,self.action_dim)\n","            #print(chosen_action)\n","            #chosen_act = np.random.choice(chosen_action,p = act)\n","            #print(chosen_act)\n","            action = np.zeros((self.action_dim))\n","            #action[:] = act[:]\n","            act = np.argmax(act)\n","            #print(act)\n","            action[act] = 1\n","            #action[chosen_act] = 1\n","            #act = chosen_act\n","          #print(act)\n","          self.epsilon = max(self.epsilon * self.epsilon_decay,0.25)\n","          #print(self.epsilon)\n","          (temp,reward,done) = self.env.step(act)\n","          #print(act,reward)\n","          next_state[:] = temp[:]\n","          #print(action)\n","          #print(curr_state,next_state,reward,done)\n","          self.memorize(curr_state, action, reward, done, next_state)\n","          (states, actions, rewards, dones, new_states, _) = self.sample_batch(self.batch_size)\n","          # Predict Target Q-Values Using Target Network\n","          q_values = self.critic.target_predict([new_states, self.actor.target_predict(new_states)])\n","          #print(q_values)\n","          # Compute Critic Target\n","          critic_target = self.bellman(rewards, q_values, dones)\n","          # Train Both Networks on Sampled Batch, Update Target Networks\n","          self.update_models(states, actions, critic_target)\n","          # Update Current State\n","          curr_state[:] = next_state[:]\n","          cumulative_reward += reward\n","          steps += 1\n","          if(steps == 10):\n","            #print(\"Fail\")\n","            break\n","        #print(steps,cumulative_reward)\n","        #print(steps)\n","        num_alterations.append(steps)\n","        cumulative_rewards.append(cumulative_reward)\n","      return (num_alterations,cumulative_rewards)\n","\n","    def evaluate(self,max_alterations):\n","        # Evaluate Agent on Test Data of 5K Malware Instances\n","        #(self.env.X,self.env.Y) = self.env.univariate_select(self.env.num_features)\n","        #self.env.X = np.copy(X_new)\n","        #self.env.Y = np.copy(Y_new)\n","        self.env.indices = np.where(self.env.Y == 1)\n","        self.env.data = self.env.X[self.env.indices[0]]\n","        # Split Malware Instances into Train and Test Data\n","        #self.env.train_size = int(np.rint(self.env.data.shape[0] * 0.8))\n","        #self.env.train_data = self.env.data[:self.env.train_size,:]\n","        #self.env.test_data = self.env.data[self.env.train_size:,:]\n","        self.env.test_data = self.env.data\n","        num_alterations = []\n","        results = []\n","        poison_data = []\n","        action_list = []\n","        max_alterations = min(max_alterations,self.observation_dim)\n","        #print(max_alterations)\n","        curr_state = np.zeros((self.observation_dim,))\n","        next_state = np.zeros((self.observation_dim,))\n","        input = self.env.test_data\n","        #print(input.shape)\n","        #for i in range(0,100):\n","        for i in range(0,input.shape[0]):\n","          #print(\"Malware Instance: \",i,max_alterations)\n","          steps,done = 0,0\n","          action_store = []\n","          curr_state[:] = input[i,:]\n","          self.env.state = input[i,:]\n","          #print(self.env.state)\n","          act = self.policy_action(curr_state)\n","          indices = act.argsort()\n","          #print(act)\n","          #print(indices)\n","          #index[::-1][:K]\n","          actions = indices[::-1][:max_alterations]\n","          #print(actions) \n","          #print(curr_state)\n","          '''while not done:\n","            #print(curr_state)\n","            act = self.policy_action(curr_state)\n","            chosen_action = np.arange(0,self.action_dim)\n","            chosen_act = np.random.choice(chosen_action,p = act)\n","            print(act,chosen_act)\n","            #act = np.argmax(act)\n","            #(temp,reward,done) = self.env.step(act)\n","            (temp,reward,done) = self.env.step(chosen_act)\n","            print(reward)\n","            #print(temp)\n","            next_state[:] = temp[:]\n","            curr_state[:] = next_state[:]\n","            steps += 1\n","            if(steps == max_alterations):\n","              #print(\"Fail\")\n","              break\n","          #print(steps)\n","          #print(curr_state)\n","          num_alterations.append(steps)\n","        return num_alterations'''\n","          for j in range(0,max_alterations):\n","            #print(self.env.state)\n","            #print(input[i,:])\n","            act = actions[j]\n","            action_store.append(act)\n","            #print(act)\n","            (temp,reward,done) = self.env.step(act)\n","            #print(act,reward,done)\n","            steps += 1\n","            if done:\n","              poison_data.append(self.env.state)\n","              break\n","          #malware_data.append(self.env.state)\n","          num_alterations.append(steps)\n","          results.append(done)\n","          action_list.append(action_store)\n","        poison_data = np.array(poison_data)\n","        return (num_alterations,results,poison_data,action_list)\n","\n","\n","    def evaluate_confusion_stats(self,max_alterations):\n","        # Evaluate Agent on Test Data of 5K Malware Instances\n","        #(self.env.X,self.env.Y) = self.env.univariate_select(self.env.num_features)\n","        #self.env.X = np.copy(X_new)\n","        #self.env.Y = np.copy(Y_new)\n","        self.env.indices = np.where(self.env.Y == 1)\n","        self.env.data = self.env.X[self.env.indices[0]]\n","        # Split Malware Instances into Train and Test Data\n","        #self.env.train_size = int(np.rint(self.env.data.shape[0] * 0.8))\n","        #self.env.train_data = self.env.data[:self.env.train_size,:]\n","        #self.env.test_data = self.env.data[self.env.train_size:,:]\n","        self.env.test_data = self.env.data\n","        num_alterations = []\n","        results = []\n","        malware_data = []\n","        action_list = []\n","        max_alterations = min(max_alterations,self.observation_dim)\n","        #print(max_alterations)\n","        curr_state = np.zeros((self.observation_dim,))\n","        next_state = np.zeros((self.observation_dim,))\n","        input = self.env.test_data\n","        #print(input.shape)\n","        #for i in range(0,100):\n","        for i in range(0,input.shape[0]):\n","          #print(\"Malware Instance: \",i,max_alterations)\n","          steps,done = 0,0\n","          action_store = []\n","          curr_state[:] = input[i,:]\n","          self.env.state = input[i,:]\n","          #print(self.env.state)\n","          act = self.policy_action(curr_state)\n","          indices = act.argsort()\n","          #print(act)\n","          #print(indices)\n","          #index[::-1][:K]\n","          actions = indices[::-1][:max_alterations]\n","          #print(actions) \n","          #print(curr_state)\n","          '''while not done:\n","            #print(curr_state)\n","            act = self.policy_action(curr_state)\n","            chosen_action = np.arange(0,self.action_dim)\n","            chosen_act = np.random.choice(chosen_action,p = act)\n","            print(act,chosen_act)\n","            #act = np.argmax(act)\n","            #(temp,reward,done) = self.env.step(act)\n","            (temp,reward,done) = self.env.step(chosen_act)\n","            print(reward)\n","            #print(temp)\n","            next_state[:] = temp[:]\n","            curr_state[:] = next_state[:]\n","            steps += 1\n","            if(steps == max_alterations):\n","              #print(\"Fail\")\n","              break\n","          #print(steps)\n","          #print(curr_state)\n","          num_alterations.append(steps)\n","        return num_alterations'''\n","          for j in range(0,max_alterations):\n","            #print(self.env.state)\n","            #print(input[i,:])\n","            act = actions[j]\n","            action_store.append(act)\n","            #print(act)\n","            (temp,reward,done) = self.env.step(act)\n","            #print(act,reward,done)\n","            steps += 1\n","            if done:\n","              #poison_data.append(self.env.state)\n","              break\n","          malware_data.append(self.env.state)\n","          num_alterations.append(steps)\n","          results.append(done)\n","          action_list.append(action_store)\n","        malware_data = np.array(malware_data)\n","        return (num_alterations,results,malware_data,action_list)\n","          \n","\n","    def save_weights(self, path, classifier):\n","        # Save Weights\n","        path += '_LR_{}'.format(self.lr)\n","        path += '_NF_{}'.format(self.observation_dim)\n","        path += '_'\n","        path += classifier \n","        self.actor.save(path)\n","        self.critic.save(path)\n","\n","    def load_weights(self, path_actor, path_critic):\n","        # Load Weights\n","        self.critic.load_weights(path_critic)\n","        self.actor.load_weights(path_actor)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AfZek1vEIF6o"},"source":["**Classifier Baseline Models**"]},{"cell_type":"code","metadata":{"id":"1O5_osuyyDUk"},"source":["X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=42)\n","baseline_path = path + 'Classifier Baseline Permission/'\n","num_features_set = [195]\n","models = ['RF','DT','BNB','SVM','LR','GB','XGB','Stack','DNN1','DNN3','DNN5']\n","#models = ['DT']\n","classifiers = {\"RF\":\"Random Forest\", \"DT\":\"Decision Tree\", \"BNB\":\"Bernoulli Naive Bayes\",\"SVM\":\"Support Vector Machine\",\"LR\":\"Logistic Regression\",\"GB\":\"Gradient Boost\",\"XGB\":\"Extreme Gradient Boost\",\"Stack\":\"Stacked - SVM + DT\",\"DNN1\":\"Neural Network - 1 Hidden Layer\",\"DNN3\":\"Neural Network - 3 Hidden Layer\",\"DNN5\":\"Neural Network - 5 Hidden Layer\"}\n","# Workbook is created \n","wb = Workbook()   \n","# add_sheet is used to create sheet. \n","sheet1 = wb.add_sheet('Sheet 1')\n","sheet1.write(0,0,'Classifier')\n","sheet1.write(0,1,'TP')\n","sheet1.write(0,2,'TN')\n","sheet1.write(0,3,'FP')\n","sheet1.write(0,4,'FN')\n","sheet1.write(0,5,'Accuracy')\n","sheet1.write(0,6,'AUC Score')\n","row = 0\n","column = 0\n","for classifier in models:\n","  method = 'classify' + classifier\n","  column = 0\n","  row = row + 1\n","  sheet1.write(row,column,classifiers.get(classifier))\n","  model,acc,_,_,_,Y_pred = eval(method)(X_train,X_test,Y_train,Y_test)\n","  TN,FP,FN,TP = confusion_matrix(Y_test,Y_pred).ravel()\n","  AUC = roc_auc_score(Y_test, Y_pred)\n","  column = column + 1\n","  sheet1.write(row,column,str(TP))\n","  column = column + 1\n","  sheet1.write(row,column,str(TN))\n","  column = column + 1\n","  sheet1.write(row,column,str(FP))\n","  column = column + 1\n","  sheet1.write(row,column,str(FN))\n","  column = column + 1\n","  sheet1.write(row,column,str((TP+TN)/(TP+TN+FP+FN)))\n","  column = column + 1\n","  sheet1.write(row,column,str(AUC))\n","  print(classifier, acc, AUC)\n","  filename = classifier + '_Classifier_NF_' + str(195) + '.pkl' \n","  pickle.dump(model, open(filename, 'wb'))\n","wb.save('Classifier Baseline Stats 70-30 Split Permission.xls')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AxTmgsHn-bbm"},"source":["**Generate Agent Models**"]},{"cell_type":"code","metadata":{"id":"Ic_RkVsUPepr"},"source":["baseline_path = path + 'Classifier Baseline Permission/'\n","agent_path = path + 'Agent Permission/'\n","num_features_set = [195]\n","num_episodes = 1000\n","#models = ['RF','DT','BNB','SVM','LR','GB','XGB','Stack','DNN1','DNN3','DNN5']\n","models = ['RF']\n","classifiers = {\"RF\":\"Random Forest\", \"DT\":\"Decision Tree\", \"BNB\":\"Bernoulli Naive Bayes\",\"SVM\":\"Support Vector Machine\",\"LR\":\"Logistic Regression\",\"GB\":\"Gradient Boost\",\"XGB\":\"Extreme Gradient Boost\",\"Stack\":\"Stacked\",\"DNN1\":\"Neural Network - 1 Hidden Layer\",\"DNN3\":\"Neural Network - 3 Hidden Layer\",\"DNN5\":\"Neural Network - 5 Hidden Layer\"}\n","for classifier in models:\n","  method = 'classify' + classifier\n","  filename = baseline_path + classifier + '_Classifier_NF_' + str(195) + '.pkl'\n","  model = pickle.load(open(filename, 'rb'))\n","  for num_feature in num_features_set:\n","    env = Env(num_feature,model)\n","    agent = Agent(env)\n","    #agent.load_weights('/content/_LR_5e-05_NF_195_XGB_actor.h5','/content/_LR_5e-05_NF_195_XGB_critic.h5')\n","    (num_steps,cumulative_reward) = agent.train(num_episodes)\n","    agent.save_weights('/content/',classifier)\n","    agent.env.X = np.copy(X)\n","    agent.env.Y = np.copy(Y)\n","    (num_alt,res,poison_data,action_list) = agent.evaluate(10) \n","    print(num_feature,10)\n","    print(sum(res)/len(res))\n","    print(len(poison_data))\n","    print(len(action_list))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0v9hl6U-F9JY"},"source":["**Attack Stats**"]},{"cell_type":"code","metadata":{"id":"0mBbTgWMBqee"},"source":["baseline_path = path + 'Classifier Baseline Permission/'\n","agent_path = path + 'Agent Permission/'\n","num_features = 195\n","num_episodes = 500\n","#max_alterations_set = [1,2,3,4,5,6,7,8,9,10]\n","max_alterations_set = [10]\n","models = ['RF','DT','BNB','SVM','LR','GB','XGB','Stack','DNN1','DNN3','DNN5']\n","#models = ['DT','BNB']\n","classifiers = {\"RF\":\"Random Forest\", \"DT\":\"Decision Tree\", \"BNB\":\"Bernoulli Naive Bayes\",\"SVM\":\"Support Vector Machine\",\"LR\":\"Logistic Regression\",\"GB\":\"Gradient Boost\",\"XGB\":\"Extreme Gradient Boost\",\"Stack\":\"Stacked\",\"DNN1\":\"Neural Network - 1 Hidden Layer\",\"DNN3\":\"Neural Network - 3 Hidden Layer\",\"DNN5\":\"Neural Network - 5 Hidden Layer\"}\n","# Workbook is created \n","wb = Workbook()   \n","for alteration in max_alterations_set:\n","  alteration_name = 'Original Classifier Fooling Rate - ' + str(alteration) + ' Alterations'\n","  sheet_name = str(alteration) + ' Bit Attack'\n","  #print(sheet_name) \n","  sheet = wb.add_sheet(sheet_name)\n","  sheet.write(0,0,'Classifier')\n","  sheet.write(0,1,'Accuracy')\n","  sheet.write(0,2,'TP')\n","  sheet.write(0,3,'TN')\n","  sheet.write(0,4,'FP')\n","  sheet.write(0,5,'FN')\n","  sheet.write(0,6,alteration_name)\n","  row = 0\n","  column = 0\n","  for classifier in models:\n","    row = row + 1\n","    column = 0\n","    sheet.write(row,column,classifiers.get(classifier))\n","    column = column + 1\n","    # Load classifier trained on original data\n","    filename = baseline_path + classifier + '_Classifier_NF_' + str(195) + '.pkl'\n","    loaded_classifier = pickle.load(open(filename, 'rb'))\n","    # print(classifier,loaded_classifier.score(X,Y))\n","    # Load Weights of previously trained Actor Critic Model\n","    filename = agent_path + '_LR_5e-05_NF_195_' + classifier\n","    actor_weights = filename + '_actor.h5'\n","    critic_weights = filename + '_critic.h5'\n","    env = Env(num_features,loaded_classifier)\n","    agent = Agent(env)\n","    agent.load_weights(actor_weights,critic_weights)\n","    # Perform Adversarial Attack and Generate Poison Data\n","    (num_alt,res,malware_data,action_list) = agent.evaluate_confusion_stats(alteration)\n","    if(alteration == 10):\n","      f = classifier + '_action_list.pkl'\n","      pickle.dump(action_list, open(f, 'wb'))  \n","    print(classifier,sum(res)/len(res),alteration)\n","    benign = X[np.where(Y==0)]\n","    #benign = benign.reshape(5721,195)\n","    #print(benign[1])\n","    #print(malware_data.shape)\n","    X_new = np.concatenate((X[0:len(benign)],malware_data), axis=0)\n","    Y_new = np.concatenate((np.zeros((len(benign),1)),np.ones((len(malware_data),1))), axis=0)\n","    #print(X_new.shape,Y_new.shape)\n","    acc = loaded_classifier.score(X_new,Y_new)\n","    sheet.write(row,column,str(acc))\n","    Y_pred = loaded_classifier.predict(X_new)\n","    TN,FP,FN,TP = confusion_matrix(Y_new,Y_pred).ravel()\n","    column = column + 1\n","    sheet.write(row,column,str(TP))\n","    column = column + 1\n","    sheet.write(row,column,str(TN))\n","    column = column + 1\n","    sheet.write(row,column,str(FP))\n","    column = column + 1\n","    sheet.write(row,column,str(FN))\n","    column = column + 1\n","    sheet.write(row,column,str(FN/(FN+TP)))\n","    #print(classifier)\n","    print(\"Accuracy : {} \\nTrue Positives : {} \\nTrue Negatives : {} \\nFalse Positives : {} \\nFalse Negatives : {}\".format(acc,TP,TN,FP,FN))\n","wb.save('Attack Stats Permission.xls')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"89bF2Di0fDZv"},"source":["**Classifier Retrained Models**"]},{"cell_type":"code","metadata":{"id":"QjHx8J7mKniT"},"source":["baseline_path = path + 'Classifier Baseline Permission/'\n","agent_path = path + 'Agent Permission/'\n","models = ['RF','DT','BNB','SVM','LR','GB','XGB','Stack','DNN1','DNN3','DNN5']\n","#models = ['DT']\n","classifiers = {\"RF\":\"Random Forest\", \"DT\":\"Decision Tree\", \"BNB\":\"Bernoulli Naive Bayes\",\"SVM\":\"Support Vector Machine\",\"LR\":\"Logistic Regression\",\"GB\":\"Gradient Boost\",\"XGB\":\"Extreme Gradient Boost\",\"Stack\":\"Stacked\",\"DNN1\":\"Neural Network - 1 Hidden Layer\",\"DNN3\":\"Neural Network - 3 Hidden Layer\",\"DNN5\":\"Neural Network - 5 Hidden Layer\"}\n","num_features = 195\n","max_alteration = 10\n","# Workbook is created \n","wb = Workbook()   \n","# add_sheet is used to create sheet. \n","sheet1 = wb.add_sheet('Sheet 1')\n","sheet1.write(0,0,'Classifier')\n","sheet1.write(0,1,'TP')\n","sheet1.write(0,2,'TN')\n","sheet1.write(0,3,'FP')\n","sheet1.write(0,4,'FN')\n","sheet1.write(0,5,'Accuracy')\n","sheet1.write(0,6,'AUC Score')\n","row = 0\n","column = 0\n","for classifier in models:\n","  row = row + 1\n","  column = 0\n","  sheet1.write(row,column,classifiers.get(classifier))\n","  # Load classifier trained on original data\n","  filename = baseline_path + classifier + '_Classifier_NF_' + str(195) + '.pkl'\n","  loaded_classifier = pickle.load(open(filename, 'rb'))\n","  # print(classifier,loaded_classifier.score(X,Y))\n","  # Load Weights of previously trained Actor Critic Model\n","  filename = agent_path + '_LR_5e-05_NF_195_' + classifier\n","  actor_weights = filename + '_actor.h5'\n","  critic_weights = filename + '_critic.h5'\n","  env = Env(num_features,loaded_classifier)\n","  agent = Agent(env)\n","  agent.load_weights(actor_weights,critic_weights)\n","  # Perform Adversarial Attack and Generate Poison Data\n","  (num_alt,res,poison_data,action_list) = agent.evaluate(max_alteration)\n","  print(sum(res)/len(res))\n","  #print(len(res))\n","  poison_data = np.array(poison_data)\n","  # Perform Oversampling of Benign Instances to Make # Malware and Benign Instances Equal\n","  benign = X[np.where(Y==0)]\n","  indices = []\n","  for i in range(0,len(poison_data)):\n","    idx = randint(0,len(benign) - 1)\n","    indices.append(idx)\n","  # Append Poison Data to Original Data with True Labels and also the Oversampled Benign Instances\n","  X_new = np.concatenate((X,poison_data), axis=0)\n","  Y_new = np.concatenate((Y,np.ones((len(poison_data),1))), axis=0)\n","  X_new = np.concatenate((X_new,X[indices]), axis = 0)\n","  Y_new = np.concatenate((Y_new,np.zeros((len(X[indices]),1))), axis=0)\n","  X_train_new, X_test_new, Y_train_new, Y_test_new = train_test_split(X_new, Y_new, test_size=0.30, random_state=42)\n","  print(X_new.shape,Y_new.shape)\n","  filename = classifier + '_X_new' \n","  pickle.dump(X_new,open(filename,'wb'))\n","  filename = classifier + '_Y_new'\n","  pickle.dump(Y_new,open(filename, 'wb'))\n","  method = 'classify' + classifier\n","  # Perform Adversarial Retraining\n","  filename = '/content/' + classifier + '_Retrained_Classifier_NF_' + str(195) + '.pkl'\n","  retrained_classifier,acc,_,_,_,Y_pred = eval(method)(X_train_new,X_test_new,Y_train_new,Y_test_new)\n","  TN,FP,FN,TP = confusion_matrix(Y_test_new,Y_pred).ravel()\n","  AUC = roc_auc_score(Y_test_new, Y_pred)\n","  column = column + 1\n","  sheet1.write(row,column,str(TP))\n","  column = column + 1\n","  sheet1.write(row,column,str(TN))\n","  column = column + 1\n","  sheet1.write(row,column,str(FP))\n","  column = column + 1\n","  sheet1.write(row,column,str(FN))\n","  column = column + 1\n","  sheet1.write(row,column,str((TP+TN)/(TP+TN+FP+FN)))\n","  column = column + 1\n","  sheet1.write(row,column,str(AUC))\n","  print(retrained_classifier, acc, AUC)\n","  pickle.dump(retrained_classifier, open(filename, 'wb'))\n","wb.save('Classifier Retrained Stats 70-30 Split Permission.xls')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wK-nIGt1k5t0"},"source":["**Baseline Class Probabilities**"]},{"cell_type":"code","metadata":{"id":"kw8tkwHZjeD_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619341861755,"user_tz":-330,"elapsed":181819,"user":{"displayName":"Sujay C Sharma","photoUrl":"","userId":"13811295421282211283"}},"outputId":"032ce2ba-177f-4e73-ec43-15ff3ced70b8"},"source":["baseline_path = path + 'Classifier Baseline Permission/'\n","models = ['RF','DT','BNB','SVM','LR','GB','XGB','Stack','DNN1','DNN3','DNN5']\n","classifiers = {\"RF\":\"Random Forest\", \"DT\":\"Decision Tree\", \"BNB\":\"Bernoulli Naive Bayes\",\"SVM\":\"Support Vector Machine\",\"LR\":\"Logistic Regression\",\"GB\":\"Gradient Boost\",\"XGB\":\"Extreme Gradient Boost\",\"Stack\":\"Stacked\",\"DNN1\":\"Neural Network - 1 Hidden Layer\",\"DNN3\":\"Neural Network - 3 Hidden Layer\",\"DNN5\":\"Neural Network - 5 Hidden Layer\"}\n","#models = ['DT']\n","# Workbook is created \n","wb = Workbook()   \n","# add_sheet is used to create sheet. \n","sheet1 = wb.add_sheet('Sheet 1')\n","sheet1.write(0,0,'Classifier')\n","sheet1.write(0,1,'Average Benign Class Probability')\n","sheet1.write(0,2,'Average Malware Class Probability')\n","row = 0\n","column = 0\n","num_features = 195\n","max_alteration = 10\n","for classifier in models:\n","  row = row + 1\n","  column = 0\n","  sheet1.write(row,column,classifiers.get(classifier))\n","  column = column + 1\n","  # Load classifier trained on original data\n","  filename = baseline_path + classifier + '_Classifier_NF_' + str(195) + '.pkl'\n","  loaded_classifier = pickle.load(open(filename, 'rb'))\n","  P = loaded_classifier.predict_proba(X)\n","  sum_benign = 0\n","  sum_malware = 0\n","  for j in range(0,25407):\n","    sum_benign += P[j][0]\n","  sheet1.write(row,column,sum_benign/25407)\n","  column = column + 1\n","  for j in range(25407,49889):\n","    sum_malware += P[j][1]\n","  sheet1.write(row,column,sum_malware/24482)\n","  print(sum_malware/24482)\n","  print(sum_benign/25407)\n","wb.save('Baseline Class Probabilities Permission')"],"execution_count":25,"outputs":[{"output_type":"stream","text":["0.9493441248459029\n","0.9448527570269973\n","0.9575131446652232\n","0.9569407503212062\n","0.8359389790012866\n","0.9117020916228472\n","0.9298877639110367\n","0.9309298362267057\n","0.893374908912967\n","0.8968223439820956\n","0.8777374711413685\n","0.881531115317107\n","0.8769535868530673\n","0.8808891488584544\n","0.9398492501776095\n","0.9431398470794855\n","0.9566939600979883\n","0.949404029464113\n","0.9556744243870245\n","0.9615930605808081\n","0.9574419332168055\n","0.9588477658498051\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SYh0xf9F232j"},"source":["**Retrained Class Probabilities**"]},{"cell_type":"code","metadata":{"id":"eCWxjIH5Qbl3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619347377541,"user_tz":-330,"elapsed":449800,"user":{"displayName":"Sujay C Sharma","photoUrl":"","userId":"13811295421282211283"}},"outputId":"cc19c49f-f42f-435e-df62-ec0326dbbf61"},"source":["baseline_path = path + 'Classifier Retrained Permission/'\n","data_path = path + 'New Dataset Permission/'\n","models = ['RF','DT','BNB','SVM','LR','GB','XGB','Stack','DNN1','DNN3','DNN5']\n","classifiers = {\"RF\":\"Random Forest\", \"DT\":\"Decision Tree\", \"BNB\":\"Bernoulli Naive Bayes\",\"SVM\":\"Support Vector Machine\",\"LR\":\"Logistic Regression\",\"GB\":\"Gradient Boost\",\"XGB\":\"Extreme Gradient Boost\",\"Stack\":\"Stacked\",\"DNN1\":\"Neural Network - 1 Hidden Layer\",\"DNN3\":\"Neural Network - 3 Hidden Layer\",\"DNN5\":\"Neural Network - 5 Hidden Layer\"}\n","#models = ['DT','BNB']\n","# Workbook is created \n","wb = Workbook()   \n","# add_sheet is used to create sheet. \n","sheet1 = wb.add_sheet('Sheet 1')\n","sheet1.write(0,0,'Classifier')\n","sheet1.write(0,1,'Average Benign Class Probability')\n","sheet1.write(0,2,'Average Malware Class Probability')\n","row = 0\n","column = 0\n","total_sum_benign = 0\n","total_sum_malware = 0\n","total_benign = 0\n","total_malware = 0\n","num_features = 195\n","max_alteration = 10\n","for classifier in models:\n","  row = row + 1\n","  column = 0\n","  sheet1.write(row,column,classifiers.get(classifier))\n","  column = column + 1\n","  # Load classifier trained on original data\n","  filename = baseline_path + classifier + '_Retrained_Classifier_NF_' + str(195) + '.pkl'\n","  loaded_classifier = pickle.load(open(filename, 'rb'))\n","  filename = data_path + classifier + '_X_new'\n","  X_new = pickle.load(open(filename, 'rb'))\n","  filename = data_path + classifier + '_Y_new'\n","  Y_new = pickle.load(open(filename, 'rb'))\n","  malware_idx = np.where(Y_new==1)[0]\n","  benign_idx = np.where(Y_new==0)[0]\n","  total_malware = total_malware + len(malware_idx)\n","  total_benign = total_benign + len(benign_idx)\n","  P = loaded_classifier.predict_proba(X_new)\n","  sum_benign = 0\n","  sum_malware = 0\n","  for j in benign_idx:\n","    sum_benign += P[j][0]\n","    total_sum_benign += P[j][0]\n","  sheet1.write(row,column,sum_benign/len(benign_idx))\n","  column = column + 1\n","  for j in malware_idx:\n","    sum_malware += P[j][1]\n","    total_sum_malware += P[j][1]\n","  sheet1.write(row,column,sum_malware/len(malware_idx))\n","  print(sum_malware/len(malware_idx))\n","  print(sum_benign/len(benign_idx))\n","row = row + 1\n","column = 0\n","sheet1.write(row,column,'All classifiers')\n","column = column + 1\n","sheet1.write(row,column,total_sum_benign/total_benign)\n","column = column + 1\n","sheet1.write(row,column,total_sum_malware/total_malware)\n","wb.save('Retrained Class Probabilities Permission')"],"execution_count":27,"outputs":[{"output_type":"stream","text":["0.9595591664508772\n","0.9605228314571479\n","0.9708543816469858\n","0.9729725029353484\n","0.8467766520643321\n","0.8971120793922908\n","0.9487838434418693\n","0.9506513791479998\n","0.9112182047754394\n","0.9142453597901667\n","0.8852668704190866\n","0.8879625930601857\n","0.87705529709693\n","0.8808906836011762\n","0.9601745961047906\n","0.9625611935227055\n","0.9678884606856191\n","0.9669297352551994\n","0.9698112163822773\n","0.9757101522725746\n","0.9720367112586951\n","0.9747327291780339\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qyy1TR48lQUP"},"source":[""],"execution_count":null,"outputs":[]}]}